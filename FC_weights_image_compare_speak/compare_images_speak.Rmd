---
title: "Face recognition by comapring distance (weigth) between image arrays"
author: "Karim Mezhoud"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    number_sections: yes
    self_contained: no
    theme: cosmo
    toc: yes
  pdf_document:
    toc: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, error=TRUE, warning =TRUE)
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
```

## set python version and anaconda environment
```{r}
# refresh session and use the default python path
#.rs.restartR()
#reticulate::use_python("/Users/Mezhoud/miniconda3/envs/Ana_Env/bin/python", required = TRUE)
#reticulate::use_python("/Users/Mezhoud/miniconda3/bin/python", required = TRUE)
reticulate::use_python("/Users/Mezhoud/venv/bin/python3", required = TRUE)
reticulate::py_config()
```

```{r}
setwd("/Volumes/DATA/learn_by_example/face_recognition/Face-Recognition_speak")
library(reticulate)
reticulate::py_module_available("tensorflow")
```

## Add new face to `images` folder

```{python}
import cv2
import numpy as np
import matplotlib.pyplot as plt
from face_functions import speak, add_to_database
os.environ['KMP_DUPLICATE_LIB_OK']='True'
 
## interactive input does not work with markdown
#name = input("Enter your Name: ")
name = "mezhoud"
speak('saving '+ name +'to database', 2)
#add_to_database(name)

```

![](images/mezhoud.jpg)

## Compile model using dataset and load weigths into model


```{python}
from keras import backend as K
import time
from multiprocessing.dummy import Pool
K.set_image_data_format('channels_first')
import cv2
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import glob
import numpy as np
from numpy import genfromtxt
import tensorflow as tf
from fr_utils import *
from inception_network import *
from face_functions import *
from keras.models import load_model
import sys


def triplet_loss_function(y_true,y_pred,alpha = 0.3):
	anchor = y_pred[0]
	positive = y_pred[1]
	negative = y_pred[2]
	pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)
	neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)
	basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)
	loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))
	return loss


if __name__=='__main__':

	speak('compiling Model.....', 1)
	model = model(input_shape = (3,96,96))
	model.compile(optimizer = 'adam', loss = triplet_loss_function, metrics = ['accuracy'])
	speak('model compile sucessful', 1)
	speak('loading weights into model, this might take sometime sir!', 1)

	#load_weights_from_FaceNet(model) 
	speak('loading weights sequence complete sir!')


```

##  Take picture for prediction 
```{python}
os.environ['KMP_DUPLICATE_LIB_OK']='True'
#image = webcam('temp.jpg')
```

## Encode dataset (images database) to arrays
```{python}
import glob
def img_to_encoding(image_path, model):
    #speak("Start encoding", 0.5)
    image = cv2.imread(image_path, 1)
    image = cv2.resize(image, (96, 96)) 
    img = image[...,::-1]
    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)
    x_train = np.array([img])
    embedding = model.predict_on_batch(x_train)
    #speak("End encoding", 0.5)
    return embedding
    
def prepare_database(model):
    database = {}
    for file in glob.glob("images/*"):
        identity = os.path.splitext(os.path.basename(file))[0]
        database[identity] = img_to_encoding(file, model)
    return(database)
    
database = prepare_database(model)
```

## Pairwise array-array distance computing

```{python}
def recognise_face(imagepath, database, model):
    encoding = img_to_encoding(imagepath, model)
    identity = None
    min_dist = 100
    for (name, db_enc) in database.items():
        dist = np.linalg.norm(db_enc - encoding)
        print('distance for %s is %s' %(name, dist))
        if dist < min_dist:
            min_dist = dist
            identity = name
    if min_dist > 0.6:
        #speak('cant recognisethe face', 2)
        return str(0)
    else:
        #speak(identity, 0.5)
        return str("Are you %s ?" %identity)


face = recognise_face("temp.jpg", database, model)
print(face)
```

