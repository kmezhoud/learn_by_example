---
title: "Particle Classification after collision (demo code in Python)"
author: "Karim Mezhoud"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: true
    fig_caption: true
    toc: true
    fig_width: 7
    fig_height: 6
    theme: cosmo
    highlight: tango
    code_folding: show #hide
    self_contained: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, error=TRUE, warning =TRUE, results = "hide")
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
```

## set python version and anaconda environment
```{r}
reticulate::use_python("/Users/Mezhoud/anaconda3/bin/python3", required = TRUE)
reticulate::py_config()
```

# Particle type classification

Welcome! 

In this challenge we want to build a machine learning model to help us recognize particles. Particles are the tiny constituant of matter generated in a collision between proton bunches at the Large Hadron Collider at CERN. 

Particles are of course of different types and identifying which particle was produced in an extremly important task for particle physicists. 

Our dataset comprises 350 independent simulated events, where each event contains labelled images of particle trajectories. 

A good model assigns the correct particle type to any particle, even the least frequent ones.

Read throught this notebook to discover more about the particles.



```{python}
#Import libraries to load and process data
import numpy as np
import pickle
```


```{python}
# replace by your own file path
pkl_file = open("download/event1.pkl", 'rb')
event1 = pickle.load(pkl_file)
np.shape(event1)
event1
```


```{python}
# get the data and target
data,target=event1[0],event1[1]
target=target.astype('int')
target
```


```{python}
# code to particle name dictionary -- more here : 
dic_types={11: "electron", 13 : "muon", 211:"pion", 321:"kaon",2212 : "proton"}
```

## Example  of a particle


```{python}
import matplotlib.pyplot as plt
plt.title(dic_types[target[0]])
plt.imshow(data[0])
plt.show()
```


![png](cirtaChallenge_files/cirtaChallenge_7_0.png)


## Distribution of particles in an event


```{python}

from collections import Counter

plt.bar(range(len(dic_types)),list(Counter(target).values()))
plt.xticks(range(len(dic_types)), [dic_types[i] for i in list(Counter(target).keys())])

plt.show()
```


![png](cirtaChallenge_files/cirtaChallenge_9_0.png)


# SVM

Let us try to predict the particle type with an SVM model from the famous sklearn library. First we split the data into training and test sets.


```{python}
from sklearn.model_selection import train_test_split

# we transform the 10x10 images into arrays of 100. You can play with that :) 
X_train, X_test, y_train, y_test = train_test_split(
    [np.concatenate((i)) for i in data], target, test_size=0.20, random_state=42)
```


```{python}
#new shape of our data
np.array(X_train).shape, np.array(y_train).shape
```




    ((2752, 100), (2752,))




```{python}
# particle distribution in our training
Counter(y_train)
```




    Counter({211: 2116, 2212: 248, 321: 379, 11: 8, 13: 1})




```{python}
from sklearn.svm import SVC
clf = SVC(gamma='auto')
clf.fit(X_train, y_train)
```




    SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
        decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
        max_iter=-1, probability=False, random_state=None, shrinking=True,
        tol=0.001, verbose=False)




```{python}
# particle distribution in our test
Counter(y_test)
```




    Counter({321: 93, 211: 516, 2212: 77, 11: 2, 13: 1})




```{python}
clf.score(X_test,y_test)
```




    0.7489114658925979



The score is already pretty good ! Let's now try to focus on less frequent particle by removing the most redundant one, the "pion"


```{python}
#we have now reduced our test sample ! 
idx_non_pion=np.where(y_test!=211)[0]
Counter(y_test[idx_non_pion])
```




    Counter({321: 93, 2212: 77, 11: 2, 13: 1})




```{python}
#let's see how our model behaves then

clf.score(np.array(X_test)[idx_non_pion],np.array(y_test)[idx_non_pion])
```




    0.0



### oups !! Our model is actually really bad then...


```{python}
#let's take a closer look at which particle type the model is predicting 
clf.predict(np.array(X_test)[idx_non_pion])
```




    array([211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211, 211,
           211, 211, 211, 211])



## It seems our model is overfitting by predicting only pions! Can you help improve it?
